{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to get a question recommendation from the three different weak supervision approaches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.model.optimization -  apex not found, won't use it. See https://nvidia.github.io/apex/\n",
      "ERROR - root -  Failed to import 'magic' (from 'python-magic' and 'python-magic-bin' on Windows). FileTypeClassifier will not perform mimetype detection on extensionless files. Please make sure the necessary OS libraries are installed if you need this functionality.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "\n",
    "from haystack.pipelines import QuestionGenerationPipeline, TranslationWrapperPipeline, QuestionAnswerGenerationPipeline\n",
    "from haystack.nodes import QuestionGenerator, TransformersTranslator, FARMReader\n",
    "from haystack.document_stores import ElasticsearchDocumentStore, InMemoryDocumentStore\n",
    "from haystack.utils import print_questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General methods needed in every of the three weak supervision approaches. The methods are used once for the third weak supervision approach, as it performs the best. The document store is the same for all three approaches, hence adding text to the document store is done only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt(txt_name: str):\n",
    "    \"Read text from file into a string\"\n",
    "    \n",
    "    dir_path = 'data/split_files/'\n",
    "    path = dir_path + txt_name \n",
    "    text1 = \"\"\n",
    "    with open(path, \"r\") as file:\n",
    "        text1 = file.read()\n",
    "\n",
    "    return text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_doc(text1):\n",
    "    \"Write text from parameter into document store\"\n",
    "    \n",
    "    docs = [{\"content\":text1}]\n",
    "\n",
    "    # use inmemorystore for fast loading of the document store, as it will only contain a single document (txt file)\n",
    "    document_store = InMemoryDocumentStore()\n",
    "    document_store.write_documents(docs)\n",
    "    return document_store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Weak supervision approach: Question Answer Generation Pipeline in combination with a Translation Wrapper Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_QA_Pipeline():\n",
    "    \"Load the pipeline with two translation models and a squad model.\"\n",
    "\n",
    "    question_generator = QuestionGenerator()\n",
    "    #reader uses locally saved \"deepset/roberta-base-squad2\" model\n",
    "    reader = FARMReader('deepset/roberta-base-squad2')\n",
    "    qag_pipeline = QuestionAnswerGenerationPipeline(question_generator, reader)\n",
    "\n",
    "    #model for in_translator \"Helsinki-NLP/opus-mt-de-en\"\n",
    "    in_translator = TransformersTranslator(\n",
    "        model_name_or_path=\"Helsinki-NLP/opus-mt-de-en\")\n",
    "\n",
    "    #model for out_translator \"Helsinki-NLP/opus-mt-en-de\"\n",
    "    out_translator = TransformersTranslator(\n",
    "        model_name_or_path=\"Helsinki-NLP/opus-mt-en-de\")\n",
    "\n",
    "    pipeline_with_translation = TranslationWrapperPipeline(input_translator=in_translator, output_translator=out_translator, pipeline=qag_pipeline)\n",
    "    return pipeline_with_translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QA Generation\n",
    "def get_QA_results(document_store, pipeline_with_translation):\n",
    "    \"returns question answer pairs created from the pipeline for a document. note that the document store always contains a single document.\"\n",
    "    for idx, document in enumerate(tqdm(document_store)):\n",
    "        print(f\"\\n * Generating questions and answers for document {idx}: {document.content[:100]}...\\n\")\n",
    "        result = pipeline_with_translation.run(documents=[document])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize pipeline of 3. weak supervision approach\n",
    "pipeline_with_translation = initialize_QA_Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WAZ.DE___167311___wirtschaft.txt'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_path = 'data/split_files/'\n",
    "\n",
    "# select a  txt file. This file will be manually uploaded into the annotation tool and then annotated based \n",
    "# on the annotators intuition and the suggested question answer pairs by the pipeline\n",
    "random_txt_file = random.choice(os.listdir(dir_path))\n",
    "random_txt_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated pairs:\n",
      " - Q:Was hat Porsche für einen halben Milliarden Euro zu bezahlen?\n",
      "      A: Geldbußen\n",
      " - Q:Was ist der Grund, warum sich die Staatsanwaltschaft im Landkreis Stuttgart entschieden hat?\n",
      "      A: der Diesel-Skandal\n",
      " - Q:An welchem Tag hat die Staatsanwaltschaft in Stuttgart beschlossen, eine Geldstrafe zu zahlen?\n",
      "      A: Dienstag\n",
      " - Q:Was war Audis Geldstrafe im Oktober?\n",
      "      A: 800 Millionen Euro\n",
      " - Q:Wie viel erhielt Audi in einer Strafe?\n",
      "      A: 800 Millionen Euro\n",
      " - Q:In welcher Stadt hatte Audi einen Streit über die Verteilung?\n",
      "      A: Braunschweig\n",
      " - Q:In Braunschweig hatte sich bereits in welchem Zuge über die Verteilung des Fahrzeugs gestritten?\n",
      "      A: Diesel-Untersuchungen\n",
      " - Q:Was hatte bereits bei Bekanntgabe der Quartalszahlen in Höhe von einer Milliarde Euro Geld zurückgezahlt?\n",
      "      A: Volkswagen\n",
      " - Q:Wie hoch waren die Bußgelder gegen VW und Audi?\n",
      "      A: eine Milliarde Euro\n",
      " - Q:Was war von VW nicht ausführlich erklärt worden?\n",
      "      A: die Geldbußen gegen VW und Audi\n"
     ]
    }
   ],
   "source": [
    "# execute all steps to print the question answer pairs suggested by the 3. weak supervision approach\n",
    "text1 = read_txt(random_txt_file)\n",
    "print(text1)\n",
    "document_store = write_doc(text1)\n",
    "result = get_QA_results(document_store, pipeline_with_translation)\n",
    "clear_output(wait=True)\n",
    "print_questions(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Weak supervision approach: Question Generation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CPU\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated questions:\n",
      " -  What does the Volkswagen-Tochter Porsche have to pay?\n",
      " -  What is the amount of money that must be paid to the Porsche?\n",
      " -  How much money must the Porsche pay for its Bußgeld?\n",
      " -  How much did Audi have to pay in fines?\n",
      " -  What was Audi accused of doing in October?\n",
      " -  How much money did Audi pay for a fine against Audi?\n",
      " -  How much money did Volkswagen receive in exchange for diesel-motors?\n",
      " -  What was the name of the company that received the money from Volkswagen and Audi?\n",
      " -  Where did the money received from VW and Audi go?\n",
      " -  Geldbußen gegen VW und Audi gingen an die jeweiligen Länderkassen.\n",
      " -  Volkswagen hatte bei der Verkündung seiner Quartalszahlen bereits Rückstellungen in Höhe von einer Milliarde Euro bekanntgegeben, wie hoch?\n",
      " -  What was the name of the marque Volkswagen?\n",
      " -  How many million Euro was the total profit of Porsche?\n",
      " -  What were the losses from the sale of the Porsches considered?\n",
      " -  How much did Audi owe Audi for dieselskandal?\n",
      " -  How many Euros did Audi pay for diesel cars?\n",
      " -  What was the total amount of the fine Audi paid for diesel vehicles?\n",
      " -  How many Stücks lägen auch Bescheide des Kraftfahrtbundesamts vor?\n",
      " -  Porsche hat keine Rechtsmittel eingelegt, was ist die Bußgeldbescheid wirksam?\n",
      " -  What is Porsches wichtigster Markt mittlerweile?\n",
      " -  What is China?\n",
      " -  How often do the Autos neuerdings go per Güterzug?\n",
      " -  How many Containers are in Chongqing?\n",
      " -  How long is the journey from Bremerhaven?\n",
      " -  What is the name of the Osnabrücker Logistik-Unternehmen Hellmann?\n",
      " -  How many days did Hellmann say the Transporte seit Anfang April organisiert?\n",
      " -  Ein Porsche war mit Goldfolie verziert – warum die Polizei ihn abschleppen ließ?\n",
      " -  What does the Volkswagen-Tochter Porsche have to pay for?\n",
      " -  What has the Staatsanwaltschaft Stuttgart decided?\n"
     ]
    }
   ],
   "source": [
    "question_generator = QuestionGenerator()\n",
    "question_generation_pipeline = QuestionGenerationPipeline(question_generator)\n",
    "for _, document in enumerate(document_store):\n",
    "    result = question_generation_pipeline.run(documents=[document])\n",
    "    # print generated questions of the pipeline\n",
    "    print_questions(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Weak supervision approach: Question Generation Pipeline in combination with a Translation Wrapper Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CPU\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 0\n",
      "INFO - haystack.modeling.utils -  Using devices: CPU\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 0\n",
      "INFO - haystack.modeling.utils -  Using devices: CPU\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated questions:\n",
      " -  What does Porsche have to pay for a half-billion euros?\n",
      " -  What is the reason the public prosecutor decided to do in the district of Stuttgart?\n",
      " -  On what date did the public prosecutor's office in Stuttgart decide to pay a fine?\n",
      " -  What was Audi's fine in October?\n",
      " -  How much did Audi receive in a penalty?\n",
      " -  In what city did Audi have a dispute over distribution?\n",
      " -  In Braunschweig had already declared a dispute over the distribution of the vehicle in the course of what?\n",
      " -  What had already returned money in the event of the announcement of its quarterly figures had already been announced in the amount of one billion euros?\n",
      " -  How much did the fines against VW and Audi amount to?\n",
      " -  What had not been explained in detail by VW?\n"
     ]
    }
   ],
   "source": [
    "# this cell loads the pipeline and prints the questions generated for the document in the pipeline\n",
    "\n",
    "\n",
    "question_generator = QuestionGenerator()\n",
    "question_generation_pipeline = QuestionGenerationPipeline(question_generator)\n",
    "\n",
    "# Define translator for input data\n",
    "in_translator = TransformersTranslator(\n",
    "    model_name_or_path=\"Helsinki-NLP/opus-mt-de-en\")\n",
    "\n",
    "# Define translator for output data\n",
    "out_translator = TransformersTranslator(\n",
    "    model_name_or_path=\"Helsinki-NLP/opus-mt-en-de\")\n",
    "\n",
    "# Put two pipelines together\n",
    "pipeline_with_translation = TranslationWrapperPipeline(\n",
    "    input_translator=in_translator, output_translator=out_translator, pipeline=question_generation_pipeline)\n",
    "\n",
    "# Get questions for the text of the document store\n",
    "for _, document in enumerate(document_store):\n",
    "    result = pipeline_with_translation.run(documents=[document])\n",
    "    #print(result)\n",
    "    print_questions(result)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
